{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from enum import Enum    \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import csv\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read file\n",
    "# read csv\n",
    "df = pd.read_csv(\"file.csv\", header=None, sep=\"\\t\") \n",
    "#  read csv chunk\n",
    "num_of_lines = 100000\n",
    "for chunk in pd.read_csv(csv_url, chunksize = num_of_lines):\n",
    "    print(chunk.shape)\n",
    "\n",
    "# read pickle\n",
    "with open('file.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "    \n",
    "# read parquet\n",
    "pd.read_parquet('file.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write file\n",
    "# write csv from df\n",
    "df.to_csv(\"data_process_q4.csv\", sep=',', index=False)\n",
    "\n",
    "# write pickle\n",
    "with open('filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# write csv\n",
    "with open(\"accuracy_score.csv\", \"a\") as f:\n",
    "    w = csv.writer(f, delimiter = ' ')\n",
    "    list_to_write = [str(best_score), str(best_estimator), \n",
    "                  str(X.columns), str(reduce_canNotPredict), str(transform_method)]\n",
    "    w.writerow(list_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "\n",
    "# plot numerical variable\n",
    "sns_plot = sns.distplot(age)\n",
    "\n",
    "# plot categorial variable\n",
    "sns_plot = sns.countplot(current_prediction)\n",
    "\n",
    "# other plots\n",
    "cur_predict_and_label.percent.plot()\n",
    "cur_predict_and_label.percent.plot.bar()\n",
    "\n",
    "\n",
    "\n",
    "## options\n",
    "# rotate 90 degrees\n",
    "sns_plot.set_xticklabels(g.get_xticklabels(), rotation=90) \n",
    "\n",
    "# size\n",
    "plt.figure(figsize = (60,10)) \n",
    "\n",
    "# save to pdf\n",
    "sns_plot.get_figure().savefig(\"output.png\")\n",
    "\n",
    "print(age.describe(percentiles=[i* (1/20) for i in range(20)] ))\n",
    "print(\"skew : \",age_none_zero.skew())\n",
    "print(\"kurt : \", age_none_zero.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### matrix\n",
    "\n",
    "# confusion matrix\n",
    "cnf_matrix = confusion_matrix(current_prediction, df.label_city_id)\n",
    "pd.crosstab(df.label_city_id, current_prediction, rownames=['Actual Species'], colnames=['Predicted Species'])\n",
    "\n",
    "\n",
    "\n",
    "# heat map\n",
    "def plot_heatmap(col_names, calc_func, df, size = (24,8)):\n",
    "    \n",
    "    plt.figure(figsize = size) \n",
    "    cor_cols = col_names\n",
    "    cor_table = np.zeros((len(cor_cols), len(cor_cols)))\n",
    "\n",
    "    for x, c1 in enumerate(cor_cols):\n",
    "        for y, c2 in enumerate(cor_cols):\n",
    "            cor_table[x][y] = calc_func(df[c1], df[c2])\n",
    "\n",
    "    sns.set(font_scale = 1.25)\n",
    "    hm = sns.heatmap(cor_table, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cor_cols, xticklabels=cor_cols)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a col to 3 cols:\n",
    "top_3 = df['top_3_city'].map(lambda x: re.sub('\\[|\\]', \"\", str(x)))  #remove [] by \"\" in x\n",
    "df[['city0', 'city1', 'city2']] = top_3.str.split(',', n=2, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert categorical variable to numerical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot learning curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
